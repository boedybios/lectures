{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e087f8b0",
   "metadata": {},
   "source": [
    "# Chapter 10: K-Nearest Neighbors\n",
    "\n",
    "**Author:** Mbah Boedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75692175",
   "metadata": {},
   "source": [
    "## Chapter Overview\n",
    "\n",
    "\n",
    "- You learn to build a classification system using the k-nearest neighbors algorithm.\n",
    "- You learn about feature extraction.\n",
    "- You learn about regression: predicting a number, like the value of a stock tomorrow, or how much a user will enjoy a movie.\n",
    "- You learn about the use cases and limitations of k-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63044924",
   "metadata": {},
   "source": [
    "## Classifying oranges vs. grapefruit [1/5]\n",
    "\n",
    "\n",
    "- Look at this fruit. Is it an orange or a grapefruit?\n",
    "- Well, I know that grapefruits are generally bigger and redder.\n",
    "\n",
    "![](./Chapter10-figure/oranges_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a44889c",
   "metadata": {},
   "source": [
    "## Classifying oranges vs. grapefruit [2/5]\n",
    "\n",
    "\n",
    "- My thought process is something like this: I have a graph in my mind.\n",
    "\n",
    "![](./Chapter10-figure/oranges_02.png)\n",
    "\n",
    "- Generally speaking, the bigger, redder fruit are grapefruits. \n",
    "- This fruit is big and red, so it’s probably a grapefruit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f4f01",
   "metadata": {},
   "source": [
    "## Classifying oranges vs. grapefruit [3/5]\n",
    "\n",
    "\n",
    "- But what if you get a fruit like this?\n",
    "\n",
    "![](./Chapter10-figure/oranges_03.png)\n",
    "\n",
    "- How would you classify this fruit? \n",
    "- One way is to look at the neighbors of this spot. \n",
    "- Take a look at the three closest neighbors of this spot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865e5c0",
   "metadata": {},
   "source": [
    "## Classifying oranges vs. grapefruit [4/5]\n",
    "\n",
    "\n",
    "![](./Chapter10-figure/oranges_04.png)\n",
    "\n",
    "- More neighbors are oranges than grapefruit. \n",
    "- So this fruit is probably an orange. \n",
    "- Congratulations: You just used the **k-nearest neighbors (KNN)** algorithm for classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fd0df",
   "metadata": {},
   "source": [
    "## Classifying oranges vs. grapefruit [5/5]\n",
    "\n",
    "\n",
    "![](./Chapter10-figure/oranges_05.png)\n",
    "\n",
    "- The KNN algorithm is simple but useful! \n",
    "- If you’re trying to classify something, you might want to try KNN first. \n",
    "- Let’s look at a more real-world example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759ea1d",
   "metadata": {},
   "source": [
    "## Building a recommendations system [1/3]\n",
    "\n",
    "\n",
    "- Suppose you’re Netflix, and you want to build a movie recommendations system for your users. \n",
    "- On a high level, this is similar to the grapefruit problem!\n",
    "- You can plot every user on a graph.\n",
    "\n",
    "![](./Chapter10-figure/netflix_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188a879",
   "metadata": {},
   "source": [
    "## Building a recommendations system [2/3]\n",
    "\n",
    "\n",
    "- These users are plotted by similarity, so users with similar taste are plotted closer together. \n",
    "- Suppose you want to recommend movies for Priyanka. \n",
    "- Find the five users closest to her.\n",
    "\n",
    "![](./Chapter10-figure/netflix_02.png)\n",
    "\n",
    "- Justin, JC, Joey, Lance, and Chris all have similar taste in movies. \n",
    "- So whatever movies they like, Priyanka will probably like too!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5685df8",
   "metadata": {},
   "source": [
    "## Building a recommendations system [3/3]\n",
    "\n",
    "\n",
    "- Once you have this graph, building a recommendations system is easy.\n",
    "- If Justin likes a movie, recommend it to Priyanka.\n",
    "\n",
    "![](./Chapter10-figure/netflix_03.png)\n",
    "\n",
    "- But there’s still a big piece missing. \n",
    "- You graphed the users by similarity.\n",
    "- How do you figure out how similar two users are?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb14488",
   "metadata": {},
   "source": [
    "## Feature extraction [1/10]\n",
    "\n",
    "\n",
    "- In the grapefruit example, you compared fruit based on **how big** they are and **how red** they are. \n",
    "- **Size** and **color** are the **features** you’re comparing. \n",
    "- Now suppose you have three fruit. You can extract the features.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8fc71",
   "metadata": {},
   "source": [
    "## Feature extraction [2/10]\n",
    "\n",
    "\n",
    "- Then you can graph the three fruit.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_02.png)\n",
    "\n",
    "- From the graph, you can tell visually that fruits A and B are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c533a8df",
   "metadata": {},
   "source": [
    "## Feature extraction [3/10]\n",
    "\n",
    "\n",
    "- Let’s measure how close they are. \n",
    "- To find the distance between two points, you use the Pythagorean formula.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_03.png)\n",
    "\n",
    "- Here’s the distance between A and B, for example.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39b8bf",
   "metadata": {},
   "source": [
    "## Feature extraction [4/10]\n",
    "\n",
    "\n",
    "- The distance between A and B is 1. \n",
    "- You can find the rest of the distances, too.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_05.png)\n",
    "\n",
    "- The distance formula confirms what you saw visually: fruits A and B are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be62c5",
   "metadata": {},
   "source": [
    "## Feature extraction [5/10]\n",
    "\n",
    "\n",
    "- Suppose you’re comparing Netflix users, instead. \n",
    "- You need some way to graph the users. \n",
    "- So, you need to convert each user to a set of coordinates, just as you did for fruit.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_06.png)\n",
    "\n",
    "- Once you can graph users, you can measure the distance between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea89d3",
   "metadata": {},
   "source": [
    "## Feature extraction [6/10]\n",
    "\n",
    "\n",
    "- Here’s how you can convert users into a set of numbers. \n",
    "- When users sign up for Netflix, have them rate some categories of movies based on how much they like those categories. \n",
    "- For each user, you now have a set of ratings!\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_07.png)\n",
    "\n",
    "- Priyanka and Justin like Romance and hate Horror. \n",
    "- Morpheus likes Action but hates Romance (he hates when a good action movie gets ruined by a cheesy romantic scene)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d919ce",
   "metadata": {},
   "source": [
    "## Feature extraction [7/10]\n",
    "\n",
    "\n",
    "- Remember how in oranges versus grapefruit, each fruit was represented by a set of two numbers? \n",
    "- Here, each user is represented by a set of five numbers.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_08.png)\n",
    "\n",
    "- A mathematician would say, instead of calculating the distance in two dimensions, you’re now calculating the distance in five dimensions. But the distance formula remains the same.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_09.png)\n",
    "\n",
    "- It just involves a set of five numbers instead of a set of two numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515bc43",
   "metadata": {},
   "source": [
    "## Feature extraction [8/10]\n",
    "\n",
    "\n",
    "- The distance formula is flexible: you could have a set of a million numbers and still use the same old distance formula to find the distance. \n",
    "- Maybe you’re wondering, “What does distance mean when you have five numbers?” \n",
    "- The distance tells you how similar those sets of numbers are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedfc09a",
   "metadata": {},
   "source": [
    "## Feature extraction [9/10]\n",
    "\n",
    "\n",
    "- Here’s the distance between Priyanka and Justin.\n",
    "\n",
    "![](./Chapter10-figure/feature_extraction_10.png)\n",
    "\n",
    "- Priyanka and Justin are pretty similar. \n",
    "- What’s the difference between Priyanka and Morpheus? Calculate the distance before moving on.\n",
    "- Did you get it right? Priyanka and Morpheus are 24 apart. \n",
    "- The distance tells you that Priyanka’s tastes are more like Justin’s than Morpheus’s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed282b68",
   "metadata": {},
   "source": [
    "## Feature extraction [10/10]\n",
    "\n",
    "\n",
    "- Great! Now recommending movies to Priyanka is easy: if Justin likes a movie, recommend it to Priyanka, and vice versa. \n",
    "- You just built a movie recommendations system!\n",
    "- If you’re a Netflix user, Netflix will keep telling you, “Please rate more movies. The more movies you rate, the better your recommendations will be.” \n",
    "- Now you know why. The more movies you rate, the more accurately Netflix can see what other users you’re similar to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e861f",
   "metadata": {},
   "source": [
    "## Exercises (K-Nearest Neighbors)\n",
    "\n",
    "\n",
    "Please refer to **page 195** of the textbook for exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f1b80",
   "metadata": {},
   "source": [
    "## Regression [1/5]\n",
    "\n",
    "\n",
    "- Suppose you want to do more than just recommend a movie: you want to guess how Priyanka will rate this movie. \n",
    "- Take the five people closest to her.\n",
    "- By the way, I keep talking about the closest five people. \n",
    "- There’s nothing special about the number 5: you could do the closest 2, or 10, or 10,000.\n",
    "- That’s why the algorithm is called k-nearest neighbors and not five-nearest neighbors!\n",
    "\n",
    "![](./Chapter10-figure/regression_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd045f98",
   "metadata": {},
   "source": [
    "## Regression [2/5]\n",
    "\n",
    "\n",
    "- Suppose you’re trying to guess a rating for Pitch Perfect. \n",
    "- Well, how did Justin, JC, Joey, Lance, and Chris rate it?\n",
    "\n",
    "![](./Chapter10-figure/regression_02.png)\n",
    "\n",
    "- You could take the average of their ratings and get 4.2 stars. That’s called **regression**. \n",
    "- These are the two basic things you’ll do with KNN:\n",
    "\n",
    "  - Classification = categorization into a group\n",
    "  - Regression = predicting a response (like a number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c2dd1",
   "metadata": {},
   "source": [
    "## Regression [3/5]\n",
    "\n",
    "\n",
    "- Regression is very useful. \n",
    "- Suppose you run a small bakery in Berkeley, and you make fresh bread every day. \n",
    "- You’re trying to predict how many loaves to make for today. You have a set of features:\n",
    "\n",
    "  - Weather on a scale of 1 to 5 (1 = bad, 5 = great).\n",
    "  - Weekend or holiday? (1 if it’s a weekend or a holiday, 0 otherwise.)\n",
    "  - Is there a game on? (1 if yes, 0 if no.)\n",
    "  \n",
    "![](./Chapter10-figure/regression_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad940c5",
   "metadata": {},
   "source": [
    "## Regression [4/5]\n",
    "\n",
    "\n",
    "- And you know how many loaves of bread you’ve sold in the past for different sets of features.\n",
    "\n",
    "![](./Chapter10-figure/regression_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd9f94",
   "metadata": {},
   "source": [
    "## Regression [5/5]\n",
    "\n",
    "\n",
    "- Today is a weekend day with good weather. \n",
    "- Based on the data you just saw, how many loaves will you sell? \n",
    "- Let’s use KNN, where K = 4. \n",
    "- First, figure out the four nearest neighbors for this point.\n",
    "\n",
    "![](./Chapter10-figure/regression_05.png)\n",
    "\n",
    "- Here are the distances. \n",
    "\n",
    "![](./Chapter10-figure/regression_06.png)\n",
    "\n",
    "- A, B, D, and E are the closest.\n",
    "- Take an average of the loaves sold on those days, and you get 218.75.\n",
    "- That’s how many loaves you should make for today!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109f8f9",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "\n",
    "\n",
    "- So far, you’ve been using the distance formula to compare the distance between two users. \n",
    "- Is this the best formula to use? \n",
    "- A common one used in practice is cosine similarity. Suppose two users are similar, but one of them is more conservative in their ratings. \n",
    "- They both loved Manmohan Desai’s Amar Akbar Anthony. Paul rated it 5 stars, but Rowan rated it 4 stars. \n",
    "- If you keep using the distance formula, these two users might not be each other’s neighbors, even though they have similar taste.\n",
    "- Cosine similarity doesn’t measure the distance between two vectors.\n",
    "- Instead, it compares the angles of the two vectors. \n",
    "- It’s better at dealing with cases like this. \n",
    "- Cosine similarity is out of the scope of this book, but look it up if you use KNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060f645",
   "metadata": {},
   "source": [
    "## Picking good features [1/4]\n",
    "\n",
    "\n",
    "- To figure out recommendations, you had users rate categories of movies. \n",
    "- What if you had them rate pictures of cats instead?\n",
    "\n",
    "![](./Chapter10-figure/good_features.png)\n",
    "\n",
    "- Then you’d find users who rated those pictures similarly. \n",
    "- This would probably be a worse recommendations engine, because the “features” don’t have a lot to do with taste in movies!\n",
    "- Or suppose you ask users to rate movies so you can give them recommendations—but you only ask them to rate Toy Story, Toy Story 2, and Toy Story 3. \n",
    "- This won’t tell you a lot about the users’ movie tastes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bf785",
   "metadata": {},
   "source": [
    "## Picking good features [2/4]\n",
    "\n",
    "\n",
    "- When you’re working with KNN, it’s really important to pick the right features to compare against. \n",
    "- Picking the right features means:\n",
    "\n",
    "  - Features that directly correlate to the movies you’re trying to recommend\n",
    "  - Features that don’t have a bias (for example, if you ask the users to only rate comedy movies, that doesn’t tell you whether they like action movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e86c3c",
   "metadata": {},
   "source": [
    "## Picking good features [3/4]\n",
    "\n",
    "\n",
    "- Do you think ratings are a good way to recommend movies? \n",
    "- Maybe I rated The Wire more highly than House Hunters, but I actually spend more time watching House Hunters. \n",
    "- How would you improve this Netflix recommendations system?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1123b9e6",
   "metadata": {},
   "source": [
    "## Picking good features [4/4]\n",
    "\n",
    "\n",
    "- Going back to the bakery: can you think of two good and two bad features you could have picked for the bakery? \n",
    "- Maybe you need to make more loaves after you advertise in the paper. \n",
    "- Or maybe you need to make more loaves on Mondays.\n",
    "\n",
    "- There’s no one right answer when it comes to picking good features. \n",
    "- You have to think about all the different things you need to consider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7d03e",
   "metadata": {},
   "source": [
    "## Exercises (K-Nearest Neighbors)\n",
    "\n",
    "\n",
    "Please refer to **page 198** of the textbook for exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06069189",
   "metadata": {},
   "source": [
    "## Introduction to machine learning\n",
    "\n",
    "\n",
    "- KNN is a really useful algorithm, and it’s your introduction to the magical world of **machine learning**! \n",
    "- **Machine learning** is all about making your computer more intelligent. \n",
    "- You already saw one example of machine learning: building a recommendations system. \n",
    "- Let’s look at some other examples.\n",
    "\n",
    "![](./Chapter10-figure/machine_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c1a14",
   "metadata": {},
   "source": [
    "## OCR [1/3]\n",
    "\n",
    "\n",
    "- OCR stands for **optical character recognition**. \n",
    "- It means you can take a photo of a page of text, and your computer will automatically read the text for you. \n",
    "- Google uses OCR to digitize books. How does OCR work?\n",
    "- For example, consider this number.\n",
    "\n",
    "![](./Chapter10-figure/ocr_01.png)\n",
    "\n",
    "- How would you automatically figure out what number this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127f14c2",
   "metadata": {},
   "source": [
    "## OCR [2/3]\n",
    "\n",
    "\n",
    "- You can use KNN for this:\n",
    "\n",
    "  - Go through a lot of images of numbers, and extract features of those numbers.\n",
    "  - When you get a new image, extract the features of that image, and see what its nearest neighbors are!\n",
    "\n",
    "- It’s the same problem as oranges versus grapefruit. \n",
    "- Generally speaking, OCR algorithms measure lines, points, and curves.\n",
    "\n",
    "![](./Chapter10-figure/ocr_02.png)\n",
    "\n",
    "- Then, when you get a new character, you can extract the same features from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d799def0",
   "metadata": {},
   "source": [
    "## OCR [3/3]\n",
    "\n",
    "\n",
    "- Feature extraction is a lot more complicated in OCR than the fruit example. \n",
    "- But it’s important to understand that even complex technologies build on simple ideas, like KNN. \n",
    "- You could use the same ideas for speech recognition or face recognition. \n",
    "- When you upload a photo to Facebook, sometimes it’s smart enough to tag people in the photo automatically. \n",
    "- That’s **machine learning** in action!\n",
    "- The first step of OCR, where you go through images of numbers and extract features, is called **training**. \n",
    "- Most machine learning algorithms have a training step: before your computer can do the task, it must be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03b134",
   "metadata": {},
   "source": [
    "## Building a spam filter [1/3]\n",
    "\n",
    "\n",
    "- Spam filters use another simple algorithm called the **Naive Bayes** classifier. \n",
    "- First, you train your **Naive Bayes** classifier on some data.\n",
    "\n",
    "![](./Chapter10-figure/spam_filter_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f7d3f",
   "metadata": {},
   "source": [
    "## Building a spam filter [2/3]\n",
    "\n",
    "\n",
    "- Suppose you get an email with the subject “collect your million dollars now!” Is it spam? \n",
    "- You can break this sentence into words. \n",
    "- Then, for each word, see what the probability is for that word to show up in a spam email. \n",
    "- For example, in this very simple model, the word million only appears in spam emails. \n",
    "- Naive Bayes figures out the probability that something is likely to be spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e467190",
   "metadata": {},
   "source": [
    "## Building a spam filter [3/3]\n",
    "\n",
    "\n",
    "- Naive Bayes has applications similar to KNN.\n",
    "- For example, you could use Naive Bayes to categorize fruit: you have a fruit that’s big and red. What’s the probability that it’s a grapefruit?\n",
    "It’s another simple algorithm that’s fairly effective. We love those algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad03df2",
   "metadata": {},
   "source": [
    "## Predicting the stock market\n",
    "\n",
    "\n",
    "- Here’s something that’s hard to do with machine learning: really predicting whether the stock market will go up or down. \n",
    "- How do you pick good features in a stock market? \n",
    "- Suppose you say that if the stock went up yesterday, it will go up today. \n",
    "- Is that a good feature? Or suppose you say that the stock will always go down in May. Will that work? \n",
    "- There’s no guaranteed way to use past numbers to predict future performance. \n",
    "- Predicting the future is hard, and it’s almost impossible when there are so many variables involved.\n",
    "\n",
    "![](./Chapter10-figure/stock_market.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0364c2e",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "\n",
    "- KNN is used for classification and regression and involves looking at the k-nearest neighbors.\n",
    "- Classification = categorization into a group.\n",
    "- Regression = predicting a response (like a number).\n",
    "- Feature extraction means converting an item (like a fruit or a user) into a list of numbers that can be compared.\n",
    "- Picking good features is an important part of a successful KNN algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
